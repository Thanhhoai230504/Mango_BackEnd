# from fastapi import FastAPI, UploadFile, File
# from fastapi.responses import JSONResponse, FileResponse
# from fastapi.middleware.cors import CORSMiddleware
# from ultralytics import YOLO
# import cv2
# import numpy as np
# import uuid
# import os
# import gdown 

# app = FastAPI(title="Mango Quality Checker API")

# # ‚úÖ B·∫≠t CORS cho frontend
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["*"],  
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )
# # ‚úÖ Link Google Drive (chia s·∫ª c√¥ng khai)
# DRIVE_URL = "https://drive.google.com/uc?id=1Huahb05L3-NGbFVIJGI_gBkqhBgOSirv"
# MODEL_PATH = "best.pt"

# # ‚úÖ T·∫£i model n·∫øu ch∆∞a t·ªìn t·∫°i
# if not os.path.exists(MODEL_PATH):
#     print("üì• ƒêang t·∫£i model t·ª´ Google Drive...")
#     gdown.download(DRIVE_URL, MODEL_PATH, quiet=False)

# # Load YOLO model
# model = YOLO(MODEL_PATH)

# # Th∆∞ m·ª•c l∆∞u ·∫£nh k·∫øt qu·∫£
# OUTPUT_DIR = "outputs"
# os.makedirs(OUTPUT_DIR, exist_ok=True)

# @app.get("/")
# async def root():
#     return {"message": "Welcome to the Mango Quality Checker API!"}

# @app.post("/predict/")
# async def predict(file: UploadFile = File(...)):
#     # ƒê·ªçc ·∫£nh t·ª´ upload
#     contents = await file.read()
#     nparr = np.frombuffer(contents, np.uint8)
#     img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

#     # Ch·∫°y d·ª± ƒëo√°n v·ªõi YOLO
#     results = model.predict(img, conf=0.5)

#     boxes = results[0].boxes
#     annotated_img = img.copy()
#     response_data = []

#     for box in boxes:
#         cls_id = int(box.cls[0].item())
#         conf = float(box.conf[0].item())
#         raw_label = model.names[cls_id]

#         # ‚úÖ Chu·∫©n h√≥a nh√£n
#         if "fresh" in raw_label.lower():
#             label = "fresh"
#             color = (0, 255, 0)
#             emoji = "‚úÖüçã"
#             message = "Xo√†i ngon r·ªìi ƒë·∫•y"
#         else:
#             label = "rotten"
#             color = (0, 0, 255)
#             emoji = "‚ùåüü§"
#             message = "Ui, xo√†i h·ªèng r·ªìi"

#         # V·∫Ω khung + text
#         x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
#         cv2.rectangle(annotated_img, (x1, y1), (x2, y2), color, 3)
#         cv2.putText(
#             annotated_img,
#             f"{label} {conf:.2f} {emoji}",
#             (x1, y1 - 10),
#             cv2.FONT_HERSHEY_SIMPLEX,
#             0.8,
#             color,
#             2
#         )

#         response_data.append({
#             "label": label,
#             "confidence": round(conf * 100, 2),
#             "emoji": emoji,
#             "message": message
#         })

#     # L∆∞u ·∫£nh ƒë√£ g·∫Øn khung
#     output_filename = f"{uuid.uuid4().hex}.jpg"
#     output_path = os.path.join(OUTPUT_DIR, output_filename)
#     cv2.imwrite(output_path, annotated_img)

#     return {
#         "results": response_data,
#         "image_url": f"/download/{output_filename}"
#     }


# @app.get("/download/{filename}")
# def download_file(filename: str):
#     file_path = os.path.join(OUTPUT_DIR, filename)
#     if os.path.exists(file_path):
#         return FileResponse(file_path, media_type="image/jpeg", filename=filename)
#     return JSONResponse(content={"error": "File not found"}, status_code=404)

#########################################



# from fastapi import FastAPI, UploadFile, File
# from fastapi.responses import JSONResponse, FileResponse
# from fastapi.middleware.cors import CORSMiddleware
# from ultralytics import YOLO
# import cv2
# import numpy as np
# import uuid
# import os
# import gdown 
# import asyncio
# from threading import Timer
# import requests
# from PIL import Image
# import io

# app = FastAPI(title="Mango Quality Checker API")

# # ‚úÖ B·∫≠t CORS cho frontend
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["*"],  
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )

# # ‚úÖ Link Google Drive (chia s·∫ª c√¥ng khai)
# DRIVE_URL = "https://drive.google.com/uc?id=1Huahb05L3-NGbFVIJGI_gBkqhBgOSirv"
# MODEL_PATH = "best.pt"

# # Global model variable to avoid reloading
# model = None

# # ‚úÖ Keep-alive mechanism
# def keep_alive():
#     try:
#         # Thay th·∫ø b·∫±ng URL c·ªßa b·∫°n tr√™n Render
#         requests.get("https://mango-backend-2htc.onrender.com/health", timeout=30)
#         print("‚úÖ Keep-alive ping sent")
#     except Exception as e:
#         print(f"‚ùå Keep-alive failed: {e}")
    
#     # Schedule next ping in 10 minutes
#     Timer(600, keep_alive).start()

# # ‚úÖ Load model m·ªôt l·∫ßn duy nh·∫•t
# async def load_model():
#     global model
#     if model is None:
#         # T·∫£i model n·∫øu ch∆∞a t·ªìn t·∫°i
#         if not os.path.exists(MODEL_PATH):
#             print("üì• ƒêang t·∫£i model t·ª´ Google Drive...")
#             gdown.download(DRIVE_URL, MODEL_PATH, quiet=False)
        
#         print("üîÑ Loading YOLO model...")
#         model = YOLO(MODEL_PATH)
#         print("‚úÖ Model loaded successfully!")

# # Th∆∞ m·ª•c l∆∞u ·∫£nh k·∫øt qu·∫£
# OUTPUT_DIR = "outputs"
# os.makedirs(OUTPUT_DIR, exist_ok=True)

# @app.on_event("startup")
# async def startup_event():
#     # Load model khi kh·ªüi ƒë·ªông
#     await load_model()
#     # B·∫Øt ƒë·∫ßu keep-alive mechanism
#     Timer(600, keep_alive).start()  # 10 minutes
#     print("üöÄ Server started with optimizations!")

# @app.get("/")
# async def root():
#     return {"message": "Welcome to the Mango Quality Checker API!", "status": "ready"}

# @app.get("/health")
# async def health_check():
#     """Health check endpoint for keep-alive"""
#     return {"status": "healthy", "model_loaded": model is not None}

# # ‚úÖ T·ªëi ∆∞u h√≥a x·ª≠ l√Ω ·∫£nh
# def optimize_image(img, max_size=1024):
#     """Resize ·∫£nh ƒë·ªÉ gi·∫£m th·ªùi gian x·ª≠ l√Ω"""
#     height, width = img.shape[:2]
#     if max(height, width) > max_size:
#         if width > height:
#             new_width = max_size
#             new_height = int((height * max_size) / width)
#         else:
#             new_height = max_size
#             new_width = int((width * max_size) / height)
        
#         img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)
#     return img

# @app.post("/predict/")
# async def predict(file: UploadFile = File(...)):
#     global model
    
#     try:
#         # ƒê·∫£m b·∫£o model ƒë√£ ƒë∆∞·ª£c load
#         if model is None:
#             await load_model()
        
#         # ‚úÖ Optimize file reading
#         contents = await file.read()
        
#         # ‚úÖ S·ª≠ d·ª•ng PIL ƒë·ªÉ ƒë·ªçc ·∫£nh nhanh h∆°n
#         image_pil = Image.open(io.BytesIO(contents))
#         img = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)
        
#         # ‚úÖ T·ªëi ∆∞u k√≠ch th∆∞·ªõc ·∫£nh
#         img = optimize_image(img, max_size=800)

#         # ‚úÖ Ch·∫°y d·ª± ƒëo√°n v·ªõi confidence th·∫•p h∆°n ƒë·ªÉ nhanh h∆°n
#         results = model.predict(img, conf=0.3, verbose=False)

#         boxes = results[0].boxes
#         annotated_img = img.copy()
#         response_data = []

#         if boxes is not None and len(boxes) > 0:
#             for box in boxes:
#                 cls_id = int(box.cls[0].item())
#                 conf = float(box.conf[0].item())
#                 raw_label = model.names[cls_id]

#                 # ‚úÖ Chu·∫©n h√≥a nh√£n
#                 if "fresh" in raw_label.lower():
#                     label = "fresh"
#                     color = (0, 255, 0)
#                     emoji = "‚úÖüçã"
#                     message = "Xo√†i ngon r·ªìi ƒë·∫•y"
#                 else:
#                     label = "rotten"
#                     color = (0, 0, 255)
#                     emoji = "‚ùåüü§"
#                     message = "Ui, xo√†i h·ªèng r·ªìi"

#                 # V·∫Ω khung + text
#                 x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
#                 cv2.rectangle(annotated_img, (x1, y1), (x2, y2), color, 2)
                
#                 # ‚úÖ Font size nh·ªè h∆°n ƒë·ªÉ v·∫Ω nhanh h∆°n
#                 cv2.putText(
#                     annotated_img,
#                     f"{label} {conf:.1f}",
#                     (x1, y1 - 5),
#                     cv2.FONT_HERSHEY_SIMPLEX,
#                     0.6,
#                     color,
#                     1
#                 )

#                 response_data.append({
#                     "label": label,
#                     "confidence": round(conf * 100, 1),  # L√†m tr√≤n √≠t h∆°n
#                     "emoji": emoji,
#                     "message": message
#                 })

#         # ‚úÖ L∆∞u ·∫£nh v·ªõi ch·∫•t l∆∞·ª£ng th·∫•p h∆°n ƒë·ªÉ nhanh h∆°n
#         output_filename = f"{uuid.uuid4().hex}.jpg"
#         output_path = os.path.join(OUTPUT_DIR, output_filename)
        
#         # Compress image
#         cv2.imwrite(output_path, annotated_img, [cv2.IMWRITE_JPEG_QUALITY, 80])

#         return {
#             "results": response_data,
#             "image_url": f"/download/{output_filename}",
#             "total_detected": len(response_data)
#         }
        
#     except Exception as e:
#         print(f"‚ùå Prediction error: {e}")
#         return JSONResponse(
#             content={"error": f"Prediction failed: {str(e)}"}, 
#             status_code=500
#         )

# @app.get("/download/{filename}")
# def download_file(filename: str):
#     file_path = os.path.join(OUTPUT_DIR, filename)
#     if os.path.exists(file_path):
#         return FileResponse(
#             file_path, 
#             media_type="image/jpeg", 
#             filename=filename,
#             headers={"Cache-Control": "public, max-age=3600"}  # Cache 1 hour
#         )
#     return JSONResponse(content={"error": "File not found"}, status_code=404)

# # ‚úÖ Endpoint warm-up
# @app.get("/warmup")
# async def warmup():
#     """Endpoint ƒë·ªÉ l√†m n√≥ng server"""
#     if model is None:
#         await load_model()
#     return {"status": "warmed up", "message": "Server is ready!"}

# if __name__ == "__main__":
#     import uvicorn
#     uvicorn.run(app, host="0.0.0.0", port=8000)




from fastapi import FastAPI, UploadFile, File, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from ultralytics import YOLO
import cv2
import numpy as np
import uuid
import os
import gdown
import asyncio
from concurrent.futures import ThreadPoolExecutor
import logging
from typing import List, Dict, Any
import time
from PIL import Image
import io

# ‚úÖ C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="Mango Quality Checker API",
    description="Fast AI-powered mango quality detection",
    version="2.0.0"
)

# ‚úÖ B·∫≠t CORS cho frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ‚úÖ C·∫•u h√¨nh model
DRIVE_URL = "https://drive.google.com/uc?id=1Huahb05L3-NGbFVIJGI_gBkqhBgOSirv"
MODEL_PATH = "best.pt"
OUTPUT_DIR = "outputs"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ‚úÖ Thread pool cho x·ª≠ l√Ω song song
executor = ThreadPoolExecutor(max_workers=2)

# ‚úÖ Global model instance
model = None

async def load_model():
    """Load model asynchronously"""
    global model
    if model is None:
        logger.info("üîÑ Loading YOLO model...")
        start_time = time.time()
        
        # T·∫£i model n·∫øu ch∆∞a t·ªìn t·∫°i
        if not os.path.exists(MODEL_PATH):
            logger.info("üì• Downloading model from Google Drive...")
            gdown.download(DRIVE_URL, MODEL_PATH, quiet=False)
        
        # Load model trong thread pool ƒë·ªÉ kh√¥ng block
        loop = asyncio.get_event_loop()
        model = await loop.run_in_executor(executor, YOLO, MODEL_PATH)
        
        load_time = time.time() - start_time
        logger.info(f"‚úÖ Model loaded in {load_time:.2f}s")
    
    return model

@app.on_event("startup")
async def startup_event():
    """Preload model on startup"""
    await load_model()
    logger.info("üöÄ API ready!")

@app.get("/")
async def root():
    return {
        "message": "Welcome to the Mango Quality Checker API!",
        "status": "ready",
        "model_loaded": model is not None
    }

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "model_ready": model is not None,
        "timestamp": time.time()
    }

def process_image_sync(img_array: np.ndarray, conf_threshold: float = 0.5) -> tuple:
    """Synchronous image processing function"""
    global model
    
    # Resize ·∫£nh n·∫øu qu√° l·ªõn ƒë·ªÉ tƒÉng t·ªëc
    height, width = img_array.shape[:2]
    max_size = 1024
    
    if max(height, width) > max_size:
        scale = max_size / max(height, width)
        new_width = int(width * scale)
        new_height = int(height * scale)
        img_array = cv2.resize(img_array, (new_width, new_height), interpolation=cv2.INTER_AREA)
        logger.info(f"üìè Resized image: {width}x{height} -> {new_width}x{new_height}")
    
    # Ch·∫°y d·ª± ƒëo√°n
    results = model.predict(img_array, conf=conf_threshold, verbose=False)
    
    boxes = results[0].boxes
    annotated_img = img_array.copy()
    response_data = []

    if boxes is not None and len(boxes) > 0:
        for i, box in enumerate(boxes):
            cls_id = int(box.cls[0].item())
            conf = float(box.conf[0].item())
            raw_label = model.names[cls_id]

            # Chu·∫©n h√≥a nh√£n
            if "fresh" in raw_label.lower():
                label = "fresh"
                color = (0, 255, 0)
                emoji = "‚úÖüçã"
                message = "Xo√†i ngon r·ªìi ƒë·∫•y"
            else:
                label = "rotten"
                color = (0, 0, 255)
                emoji = "‚ùåüü§"
                message = "Ui, xo√†i h·ªèng r·ªìi"

            # V·∫Ω khung + text
            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
            
            # V·∫Ω khung d√†y h∆°n v√† r√µ h∆°n
            cv2.rectangle(annotated_img, (x1, y1), (x2, y2), color, 4)
            
            # V·∫Ω background cho text
            text = f"{label} {conf:.2f}"
            (text_width, text_height), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)
            cv2.rectangle(annotated_img, (x1, y1 - text_height - 10), (x1 + text_width, y1), color, -1)
            
            # V·∫Ω text
            cv2.putText(
                annotated_img,
                text,
                (x1, y1 - 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.8,
                (255, 255, 255),  # Text m√†u tr·∫Øng
                2
            )

            response_data.append({
                "id": i + 1,
                "label": label,
                "confidence": round(conf * 100, 2),
                "emoji": emoji,
                "message": message,
                "bbox": [x1, y1, x2, y2]
            })
    
    return annotated_img, response_data

@app.post("/predict/")
async def predict(file: UploadFile = File(...)):
    """Fast prediction endpoint with optimizations"""
    start_time = time.time()
    
    try:
        # Validate file
        if not file.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="File must be an image")
        
        # Ensure model is loaded
        current_model = await load_model()
        if current_model is None:
            raise HTTPException(status_code=503, detail="Model not ready")
        
        # ƒê·ªçc ·∫£nh
        contents = await file.read()
        read_time = time.time()
        logger.info(f"üìñ File read in {read_time - start_time:.3f}s")
        
        # Decode ·∫£nh
        nparr = np.frombuffer(contents, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        if img is None:
            raise HTTPException(status_code=400, detail="Invalid image format")
        
        decode_time = time.time()
        logger.info(f"üñºÔ∏è Image decoded in {decode_time - read_time:.3f}s")
        
        # X·ª≠ l√Ω ·∫£nh trong thread pool
        loop = asyncio.get_event_loop()
        annotated_img, response_data = await loop.run_in_executor(
            executor, 
            process_image_sync, 
            img, 
            0.5
        )
        
        process_time = time.time()
        logger.info(f"ü§ñ AI processing in {process_time - decode_time:.3f}s")
        
        # L∆∞u ·∫£nh v·ªõi ch·∫•t l∆∞·ª£ng t·ªëi ∆∞u
        output_filename = f"{uuid.uuid4().hex}.jpg"
        output_path = os.path.join(OUTPUT_DIR, output_filename)
        
        # S·ª≠ d·ª•ng compression ƒë·ªÉ gi·∫£m k√≠ch th∆∞·ªõc file
        cv2.imwrite(output_path, annotated_img, [cv2.IMWRITE_JPEG_QUALITY, 85])
        
        save_time = time.time()
        logger.info(f"üíæ Image saved in {save_time - process_time:.3f}s")
        
        total_time = save_time - start_time
        logger.info(f"‚ö° Total processing time: {total_time:.3f}s")
        
        return {
            "success": True,
            "results": response_data,
            "image_url": f"/download/{output_filename}",
            "processing_time": round(total_time, 3),
            "total_detections": len(response_data),
            "image_size": f"{img.shape[1]}x{img.shape[0]}"
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error in prediction: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Prediction failed: {str(e)}")

@app.get("/download/{filename}")
async def download_file(filename: str):
    """Optimized file download with caching headers"""
    file_path = os.path.join(OUTPUT_DIR, filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="File not found")
    
    return FileResponse(
        file_path, 
        media_type="image/jpeg", 
        filename=filename,
        headers={
            "Cache-Control": "public, max-age=3600",  # Cache 1 hour
            "ETag": filename
        }
    )

# ‚úÖ Background task ƒë·ªÉ d·ªçn d·∫πp file c≈©
@app.on_event("startup")
async def cleanup_old_files():
    """Clean up old files periodically"""
    async def cleanup():
        while True:
            try:
                current_time = time.time()
                for filename in os.listdir(OUTPUT_DIR):
                    file_path = os.path.join(OUTPUT_DIR, filename)
                    if os.path.isfile(file_path):
                        file_age = current_time - os.path.getctime(file_path)
                        # X√≥a file c≈© h∆°n 1 gi·ªù
                        if file_age > 3600:
                            os.remove(file_path)
                            logger.info(f"üóëÔ∏è Cleaned up old file: {filename}")
            except Exception as e:
                logger.error(f"Error in cleanup: {e}")
            
            # Ch·∫°y cleanup m·ªói 30 ph√∫t
            await asyncio.sleep(1800)
    
    asyncio.create_task(cleanup())

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app", 
        host="0.0.0.0", 
        port=8000, 
        reload=False,  # T·∫Øt reload trong production
        workers=1,     # Single worker cho model consistency
        log_level="info"
    )