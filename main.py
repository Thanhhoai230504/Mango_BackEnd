# from fastapi import FastAPI, UploadFile, File
# from fastapi.responses import JSONResponse, FileResponse
# from fastapi.middleware.cors import CORSMiddleware
# from ultralytics import YOLO
# import cv2
# import numpy as np
# import uuid
# import os
# import gdown 

# app = FastAPI(title="Mango Quality Checker API")

# # ‚úÖ B·∫≠t CORS cho frontend
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["*"],  
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )
# # ‚úÖ Link Google Drive (chia s·∫ª c√¥ng khai)
# DRIVE_URL = "https://drive.google.com/uc?id=1Huahb05L3-NGbFVIJGI_gBkqhBgOSirv"
# MODEL_PATH = "best.pt"

# # ‚úÖ T·∫£i model n·∫øu ch∆∞a t·ªìn t·∫°i
# if not os.path.exists(MODEL_PATH):
#     print("üì• ƒêang t·∫£i model t·ª´ Google Drive...")
#     gdown.download(DRIVE_URL, MODEL_PATH, quiet=False)

# # Load YOLO model
# model = YOLO(MODEL_PATH)

# # Th∆∞ m·ª•c l∆∞u ·∫£nh k·∫øt qu·∫£
# OUTPUT_DIR = "outputs"
# os.makedirs(OUTPUT_DIR, exist_ok=True)

# @app.get("/")
# async def root():
#     return {"message": "Welcome to the Mango Quality Checker API!"}

# @app.post("/predict/")
# async def predict(file: UploadFile = File(...)):
#     # ƒê·ªçc ·∫£nh t·ª´ upload
#     contents = await file.read()
#     nparr = np.frombuffer(contents, np.uint8)
#     img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

#     # Ch·∫°y d·ª± ƒëo√°n v·ªõi YOLO
#     results = model.predict(img, conf=0.5)

#     boxes = results[0].boxes
#     annotated_img = img.copy()
#     response_data = []

#     for box in boxes:
#         cls_id = int(box.cls[0].item())
#         conf = float(box.conf[0].item())
#         raw_label = model.names[cls_id]

#         # ‚úÖ Chu·∫©n h√≥a nh√£n
#         if "fresh" in raw_label.lower():
#             label = "fresh"
#             color = (0, 255, 0)
#             emoji = "‚úÖüçã"
#             message = "Xo√†i ngon r·ªìi ƒë·∫•y"
#         else:
#             label = "rotten"
#             color = (0, 0, 255)
#             emoji = "‚ùåüü§"
#             message = "Ui, xo√†i h·ªèng r·ªìi"

#         # V·∫Ω khung + text
#         x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
#         cv2.rectangle(annotated_img, (x1, y1), (x2, y2), color, 3)
#         cv2.putText(
#             annotated_img,
#             f"{label} {conf:.2f} {emoji}",
#             (x1, y1 - 10),
#             cv2.FONT_HERSHEY_SIMPLEX,
#             0.8,
#             color,
#             2
#         )

#         response_data.append({
#             "label": label,
#             "confidence": round(conf * 100, 2),
#             "emoji": emoji,
#             "message": message
#         })

#     # L∆∞u ·∫£nh ƒë√£ g·∫Øn khung
#     output_filename = f"{uuid.uuid4().hex}.jpg"
#     output_path = os.path.join(OUTPUT_DIR, output_filename)
#     cv2.imwrite(output_path, annotated_img)

#     return {
#         "results": response_data,
#         "image_url": f"/download/{output_filename}"
#     }


# @app.get("/download/{filename}")
# def download_file(filename: str):
#     file_path = os.path.join(OUTPUT_DIR, filename)
#     if os.path.exists(file_path):
#         return FileResponse(file_path, media_type="image/jpeg", filename=filename)
#     return JSONResponse(content={"error": "File not found"}, status_code=404)

#########################################
from fastapi import FastAPI, UploadFile, File
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from ultralytics import YOLO
import cv2
import numpy as np
import uuid
import os
import gdown 

app = FastAPI(title="Mango Quality Checker API")

# ‚úÖ B·∫≠t CORS cho frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ‚úÖ Link Google Drive (chia s·∫ª c√¥ng khai)
DRIVE_URL = "https://drive.google.com/uc?id=1Huahb05L3-NGbFVIJGI_gBkqhBgOSirv"
MODEL_PATH = "best.pt"

# ‚úÖ T·∫£i model n·∫øu ch∆∞a t·ªìn t·∫°i
if not os.path.exists(MODEL_PATH):
    print("üì• ƒêang t·∫£i model t·ª´ Google Drive...")
    gdown.download(DRIVE_URL, MODEL_PATH, quiet=False)

# ‚úÖ Lazy-load YOLO model
model = None  

def get_model():
    global model
    if model is None:
        model = YOLO(MODEL_PATH)  # load khi l·∫ßn ƒë·∫ßu predict
    return model

# Th∆∞ m·ª•c l∆∞u ·∫£nh k·∫øt qu·∫£
OUTPUT_DIR = "outputs"
os.makedirs(OUTPUT_DIR, exist_ok=True)

@app.get("/")
async def root():
    return {"message": "Welcome to the Mango Quality Checker API!"}

@app.post("/predict/")
async def predict(file: UploadFile = File(...)):
    # ƒê·ªçc ·∫£nh t·ª´ upload
    contents = await file.read()
    nparr = np.frombuffer(contents, np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

    # ‚úÖ L·∫•y model (lazy-load)
    model = get_model()
    results = model.predict(img, conf=0.5)

    boxes = results[0].boxes
    annotated_img = img.copy()
    response_data = []

    for box in boxes:
        cls_id = int(box.cls[0].item())
        conf = float(box.conf[0].item())
        raw_label = model.names[cls_id]

        # ‚úÖ Chu·∫©n h√≥a nh√£n
        if "fresh" in raw_label.lower():
            label = "fresh"
            color = (0, 255, 0)
            emoji = "‚úÖüçã"
            message = "Xo√†i ngon r·ªìi ƒë·∫•y"
        else:
            label = "rotten"
            color = (0, 0, 255)
            emoji = "‚ùåüü§"
            message = "Ui, xo√†i h·ªèng r·ªìi"

        # V·∫Ω khung + text
        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
        cv2.rectangle(annotated_img, (x1, y1), (x2, y2), color, 3)
        cv2.putText(
            annotated_img,
            f"{label} {conf:.2f} {emoji}",
            (x1, y1 - 10),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.8,
            color,
            2
        )

        response_data.append({
            "label": label,
            "confidence": round(conf * 100, 2),
            "emoji": emoji,
            "message": message
        })

    # L∆∞u ·∫£nh ƒë√£ g·∫Øn khung
    output_filename = f"{uuid.uuid4().hex}.jpg"
    output_path = os.path.join(OUTPUT_DIR, output_filename)
    cv2.imwrite(output_path, annotated_img)

    return {
        "results": response_data,
        "image_url": f"/download/{output_filename}"
    }

@app.get("/download/{filename}")
def download_file(filename: str):
    file_path = os.path.join(OUTPUT_DIR, filename)
    if os.path.exists(file_path):
        return FileResponse(file_path, media_type="image/jpeg", filename=filename)
    return JSONResponse(content={"error": "File not found"}, status_code=404)
##############################################




# from fastapi import FastAPI, UploadFile, File
# from fastapi.responses import JSONResponse, FileResponse
# from fastapi.middleware.cors import CORSMiddleware
# from ultralytics import YOLO
# import cv2
# import numpy as np
# import uuid
# import os
# import gdown 
# import asyncio
# from threading import Timer
# import requests
# from PIL import Image
# import io

# app = FastAPI(title="Mango Quality Checker API")

# # ‚úÖ B·∫≠t CORS cho frontend
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["*"],  
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )

# # ‚úÖ Link Google Drive (chia s·∫ª c√¥ng khai)
# DRIVE_URL = "https://drive.google.com/uc?id=1Huahb05L3-NGbFVIJGI_gBkqhBgOSirv"
# MODEL_PATH = "best.pt"

# # Global model variable to avoid reloading
# model = None

# # ‚úÖ Keep-alive mechanism
# def keep_alive():
#     try:
#         # Thay th·∫ø b·∫±ng URL c·ªßa b·∫°n tr√™n Render
#         requests.get("https://mango-backend-2htc.onrender.com/health", timeout=30)
#         print("‚úÖ Keep-alive ping sent")
#     except Exception as e:
#         print(f"‚ùå Keep-alive failed: {e}")
    
#     # Schedule next ping in 10 minutes
#     Timer(600, keep_alive).start()

# # ‚úÖ Load model m·ªôt l·∫ßn duy nh·∫•t
# async def load_model():
#     global model
#     if model is None:
#         # T·∫£i model n·∫øu ch∆∞a t·ªìn t·∫°i
#         if not os.path.exists(MODEL_PATH):
#             print("üì• ƒêang t·∫£i model t·ª´ Google Drive...")
#             gdown.download(DRIVE_URL, MODEL_PATH, quiet=False)
        
#         print("üîÑ Loading YOLO model...")
#         model = YOLO(MODEL_PATH)
#         print("‚úÖ Model loaded successfully!")

# # Th∆∞ m·ª•c l∆∞u ·∫£nh k·∫øt qu·∫£
# OUTPUT_DIR = "outputs"
# os.makedirs(OUTPUT_DIR, exist_ok=True)

# @app.on_event("startup")
# async def startup_event():
#     # Load model khi kh·ªüi ƒë·ªông
#     await load_model()
#     # B·∫Øt ƒë·∫ßu keep-alive mechanism
#     Timer(600, keep_alive).start()  # 10 minutes
#     print("üöÄ Server started with optimizations!")

# @app.get("/")
# async def root():
#     return {"message": "Welcome to the Mango Quality Checker API!", "status": "ready"}

# @app.get("/health")
# async def health_check():
#     """Health check endpoint for keep-alive"""
#     return {"status": "healthy", "model_loaded": model is not None}

# # ‚úÖ T·ªëi ∆∞u h√≥a x·ª≠ l√Ω ·∫£nh
# def optimize_image(img, max_size=1024):
#     """Resize ·∫£nh ƒë·ªÉ gi·∫£m th·ªùi gian x·ª≠ l√Ω"""
#     height, width = img.shape[:2]
#     if max(height, width) > max_size:
#         if width > height:
#             new_width = max_size
#             new_height = int((height * max_size) / width)
#         else:
#             new_height = max_size
#             new_width = int((width * max_size) / height)
        
#         img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)
#     return img

# @app.post("/predict/")
# async def predict(file: UploadFile = File(...)):
#     global model
    
#     try:
#         # ƒê·∫£m b·∫£o model ƒë√£ ƒë∆∞·ª£c load
#         if model is None:
#             await load_model()
        
#         # ‚úÖ Optimize file reading
#         contents = await file.read()
        
#         # ‚úÖ S·ª≠ d·ª•ng PIL ƒë·ªÉ ƒë·ªçc ·∫£nh nhanh h∆°n
#         image_pil = Image.open(io.BytesIO(contents))
#         img = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)
        
#         # ‚úÖ T·ªëi ∆∞u k√≠ch th∆∞·ªõc ·∫£nh
#         img = optimize_image(img, max_size=800)

#         # ‚úÖ Ch·∫°y d·ª± ƒëo√°n v·ªõi confidence th·∫•p h∆°n ƒë·ªÉ nhanh h∆°n
#         results = model.predict(img, conf=0.3, verbose=False)

#         boxes = results[0].boxes
#         annotated_img = img.copy()
#         response_data = []

#         if boxes is not None and len(boxes) > 0:
#             for box in boxes:
#                 cls_id = int(box.cls[0].item())
#                 conf = float(box.conf[0].item())
#                 raw_label = model.names[cls_id]

#                 # ‚úÖ Chu·∫©n h√≥a nh√£n
#                 if "fresh" in raw_label.lower():
#                     label = "fresh"
#                     color = (0, 255, 0)
#                     emoji = "‚úÖüçã"
#                     message = "Xo√†i ngon r·ªìi ƒë·∫•y"
#                 else:
#                     label = "rotten"
#                     color = (0, 0, 255)
#                     emoji = "‚ùåüü§"
#                     message = "Ui, xo√†i h·ªèng r·ªìi"

#                 # V·∫Ω khung + text
#                 x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
#                 cv2.rectangle(annotated_img, (x1, y1), (x2, y2), color, 2)
                
#                 # ‚úÖ Font size nh·ªè h∆°n ƒë·ªÉ v·∫Ω nhanh h∆°n
#                 cv2.putText(
#                     annotated_img,
#                     f"{label} {conf:.1f}",
#                     (x1, y1 - 5),
#                     cv2.FONT_HERSHEY_SIMPLEX,
#                     0.6,
#                     color,
#                     1
#                 )

#                 response_data.append({
#                     "label": label,
#                     "confidence": round(conf * 100, 1),  # L√†m tr√≤n √≠t h∆°n
#                     "emoji": emoji,
#                     "message": message
#                 })

#         # ‚úÖ L∆∞u ·∫£nh v·ªõi ch·∫•t l∆∞·ª£ng th·∫•p h∆°n ƒë·ªÉ nhanh h∆°n
#         output_filename = f"{uuid.uuid4().hex}.jpg"
#         output_path = os.path.join(OUTPUT_DIR, output_filename)
        
#         # Compress image
#         cv2.imwrite(output_path, annotated_img, [cv2.IMWRITE_JPEG_QUALITY, 80])

#         return {
#             "results": response_data,
#             "image_url": f"/download/{output_filename}",
#             "total_detected": len(response_data)
#         }
        
#     except Exception as e:
#         print(f"‚ùå Prediction error: {e}")
#         return JSONResponse(
#             content={"error": f"Prediction failed: {str(e)}"}, 
#             status_code=500
#         )

# @app.get("/download/{filename}")
# def download_file(filename: str):
#     file_path = os.path.join(OUTPUT_DIR, filename)
#     if os.path.exists(file_path):
#         return FileResponse(
#             file_path, 
#             media_type="image/jpeg", 
#             filename=filename,
#             headers={"Cache-Control": "public, max-age=3600"}  # Cache 1 hour
        # )
#     return JSONResponse(content={"error": "File not found"}, status_code=404)

# # ‚úÖ Endpoint warm-up
# @app.get("/warmup")
# async def warmup():
#     """Endpoint ƒë·ªÉ l√†m n√≥ng server"""
#     if model is None:
#         await load_model()
#     return {"status": "warmed up", "message": "Server is ready!"}

# if __name__ == "__main__":
#     import uvicorn
#     uvicorn.run(app, host="0.0.0.0", port=8000)